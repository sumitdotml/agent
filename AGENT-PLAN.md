# 2-Hour Hackathon Agent Plan (Experiment â†’ Prototype â†’ Demo)

## Why weâ€™re doing this
In a 2-hour hackathon, we canâ€™t build a full production agent. But we *can* build a convincing prototype that demonstrates the core properties judges associate with an â€œAI agent,â€ not just an LLM app.

Our current work is an experiment that proves the agent loop works end-to-end:
- the system **observes**
- **decides** what to do next
- **acts** via tools
- **updates state**
- **loops**
- **stops** with a final answer

This is the minimum unit of â€œagentic behaviorâ€ that can be demoed reliably under time constraints.

---

## Concrete definition: what â€œAI agentâ€ means (in this hackathon context)
**An AI agent is a goal-directed system where an LLM is used as a decision policy that:**
1. **observes state** (inputs, context, tool outputs),
2. **selects actions** (tool calls or finalization),
3. **executes actions** in an environment (tools / APIs / files / DB),
4. **incorporates feedback** from those actions back into state,
5. **repeats** until a **termination condition** is met.

This is different from:
- a chatbot (reactive Qâ†’A),
- RAG (retrieveâ†’answer),
- fixed workflows (no decision making),
- pipelines (no branching policy).

The â€œagentâ€ is specifically the **control loop**: the model decides *what to do next* based on the evolving state.

---

## What we built so far: a Minimum Viable Agent (MVA)

### 1) The â€œagent loopâ€ (concept)
The agentâ€™s behavior can be expressed as a loop:

1. **THINK**: decide next action (tool or final)
2. **ACT**: execute tool if chosen
3. **OBSERVE**: capture tool result in state
4. **repeat** until **FINAL**

This is the smallest system that still counts as an agent.

### 2) Why we used structured JSON actions
We force the model to output *only* valid JSON with one of two schemas:

- Tool call:
  ```json
  {
    "type": "tool",
    "thought_summary": "one short sentence",
    "name": "calculator",
    "input": { "expression": "(2+3)*4" }
  }

- Final answer:

```json
{
  "type": "final",
  "thought_summary": "one short sentence",
  "answer": "..."
}
```

This achieves:

- reliability: less ambiguity than free-form text
- observability: we can show the decision trajectory to judges
- tool routing: deterministic handling of tool calls
- safety: we do not request raw chain-of-thought; we request a one-sentence â€œthought summaryâ€

In hackathons, this is huge: it makes the system feel â€œagenticâ€ because decisions are explicit.

### 3) Why we adopted LangGraph

LangGraph is a graph/state-machine framework for agent workflows. Instead of writing `while True: loops` manually, we define:

- State: what the agent â€œknowsâ€ and carries forward
- Nodes: steps like THINK, TOOL, FINALIZE
- Edges: transitions between steps
- Conditional edges: logic to route based on the model decision
- END: termination of the run

This makes the agent:

- easier to reason about
- easier to debug
- easier to demo (because state transitions are explicit)
- streamable (we can show node-by-node execution as a timeline)

### 4) The state machine we implemented (core agent architecture)

#### State

We used a minimal shared state object:
- goal: what the agent is trying to accomplish
- history: a list of events (user input, assistant actions, tool outputs)
- action: the most recent structured decision from the model
- final: the final answer (when done)

This is the bare minimum to demonstrate â€œmemoryâ€ and feedback.

#### Nodes
We built three nodes:

Node A â€” `think`
- Input: current state
- Output: action (tool call or final)

Implementation idea:
- Convert state into messages (system prompt + history + goal)
- Call model (OpenRouter via an OpenAI-compatible endpoint)
- Parse model output as JSON into state["action"]

This is the â€œpolicy stepâ€ of the agent.

Node B â€” `tool`
- Input: state["action"] describing a tool call
- Output: appended tool result in history

Implementation idea:
- Execute the specified tool function (e.g., calculator)
- Append a tool-result event to history
- Return to THINK

This is the â€œacting in the environmentâ€ step.

Node C â€” `finalize`
-Input: state["action"] describing a final response
- Output: set state["final"]

This is the â€œterminationâ€ step.

#### Edges (transitions)
- START â†’ THINK
- THINK â†’ TOOL (if action.type == "tool")
- THINK â†’ FINALIZE (if action.type == "final")
- TOOL â†’ THINK (loop)
- FINALIZE â†’ END

This is the essence of â€œagentâ€.

### Why the first version felt â€œless agenticâ€
The earlier implementation produced only the final answer. Even though it was an agent internally, the demo experience looked like a normal app.

**Agentic feel requires observability.**

Judges and users need to see:
- "what it decided"
- "what tool it used"
- "what came back"
- "why it stopped"

So we upgraded to streaming, where we render the execution as an â€œagent timelineâ€.

### Streaming: making the agent feel alive (without exposing chain-of-thought)

#### What we want to stream

We stream "agent trace" events, not private chain-of-thought:

- ğŸ§  THINK: one-sentence summary
- ğŸ”§ TOOL_CHOICE: tool name + args
- ğŸ“¥ TOOL_RESULT: tool output
- âœ… FINAL: final response

#### How LangGraph helps

LangGraph can stream node updates as the graph executes.

#### Why OpenRouter is used and how it fits

We use OpenRouter because it lets us quickly swap models with minimal integration friction.

OpenRouter is compatible with OpenAI-style chat-completions endpoints (base URL + api key), so we can use libraries that expect OpenAI-like APIs while still choosing models via OpenRouter.

This is useful in a hackathon because:

- we can test a fast model for tool decisions
- we can switch to a higher-quality model for final text if needed
- we can use one integration for multiple LLM options

#### What our prototype currently demonstrates (and what it does not)

**It demonstrates:**
- âœ… Goal-directed loop
- âœ… LLM as controller (policy)
- âœ… Tool use (actions)
- âœ… Feedback integration (tool results go back into state)
- âœ… Termination condition (final output)
- âœ… Streaming trace (agent timeline)

**It does not yet demonstrate (but can):**
- â¬œ Multi-tool environment (email, calendar, DB, CRM, ticketing, docs, etc.)
- â¬œ Structured long-term memory (beyond a simple history list)
- â¬œ Robust error recovery and retries
- â¬œ Permissions, audit logs, and policy checks
- â¬œ Multi-agent coordination (optional for hackathon)

For a 2-hour hackathon, we do not need most of the above. But we should architect so they can be added incrementally.

### How this connects to â€œreal-worldâ€ (corporate / human-impact) use cases

In the real world, an agent is valuable when it can:

- reduce manual steps
- move information across systems
- enforce consistent policies
- triage, summarize, and execute actions safely

Common corporate â€œagentâ€ patterns:

- support triage agent (read ticket â†’ ask clarifying questions â†’ draft response â†’ escalate)
- meeting assistant (extract action items â†’ create tasks â†’ notify stakeholders)
- ops agent (inspect logs â†’ run checks â†’ propose fixes â†’ open PR)
- procurement / HR agent (collect requirements â†’ generate forms â†’ route approvals)

All of those can be reduced to:

- a state machine
- tool calls to relevant systems
- safe, observable decision-making

Our prototype is the skeleton that can power any of these.

### Our near-term roadmap (toward a hackathon-grade demo)

#### Phase 1 â€” â€œAgent Coreâ€ (done)
Phase 1 â€” â€œAgent Coreâ€ (done)
- agent loop via LangGraph
- structured actions (JSON)
- one tool
- streaming CLI timeline

#### Phase 2 â€” â€œAgent Demo UIâ€ (next)
- Goal: make it feel like an agent.

We will build a tiny web UI that shows:

- left: goal + inputs
- right: live timeline of events (think/tool/result/final)
- optional: â€œstate inspectorâ€ panel showing the current state object

Streaming mechanism options:

- Server-Sent Events (SSE) over FastAPI
- Streamlit with incremental UI updates
- WebSocket (optional, heavier)

SSE is often ideal for quick hackathons: simple and reliable.

#### Phase 3 â€” â€œReal-world toolsetâ€ (only if time allows)
Replace the calculator with one or two real tools:

- SQLite query tool (corporate KPI / ops data)
- local file search + summarizer (policy docs / specs)
- ticket mock API tool (simulate corporate workflows)

Pick tools that make the agent feel â€œrealâ€ without requiring enterprise access.

**What success looks like to judges**

A strong 2-hour agent demo shows:

- A clear goal and constraints
- A visible loop (not one-shot completion)
- Tool choice and tool usage are explicit and correct
- Output is grounded in tool results (not hallucinated)
- A clean â€œagent timelineâ€ makes the process obvious
- Safety posture: no raw chain-of-thought, controlled tools, bounded steps

In other words: agency + correctness + observability.

### Summary

We are building a hackathon-grade AI agent by focusing on the irreducible core:

- The agent is a controller loop (policy â†’ actions â†’ feedback â†’ termination).
- LangGraph expresses this loop as a state machine with nodes and edges.
- We enforce structured decisions via JSON actions for reliability.
- We stream the run as an agent timeline to make it feel truly agentic.
- Next: a web UI that streams these events in real time (SSE/Streamlit).

This gives us a credible â€œagentâ€ foundation that can later be pointed at real-world tools (work/corporate/human-impact), without changing the agent core.
